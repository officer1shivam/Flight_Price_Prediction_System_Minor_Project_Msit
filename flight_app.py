# -*- coding: utf-8 -*-
"""Flight ticket price prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SAQYYiUNwImnjKaD3o2LlxJmriwVq2YK

# **Flight's ticket Price Prediction Model**
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

"""# Importing all the essential libraries for this project"""

# importing libraries
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import Pipeline

df_train = pd.read_csv(r"C:\Users\Dell\Downloads\project\train.csv")
df_train.info()

df_test = pd.read_csv(r"C:\Users\Dell\Downloads\project\test.csv")
df_test.info()

df_train.drop(columns=["id"]).describe().T

print(df_train.isna().sum())
print("*"*40)
print(df_test.isna().sum())

for data in [df_train, df_test]:
    for col in data.columns:
        if data[col].dtype == 'object':
            data[col] = data[col].fillna("Unknown")
        else:
            data[col] = data[col].fillna(data[col].median())

print(df_train.isna().sum())
print("*"*40)
print(df_test.isna().sum())

df_train = df_train.drop_duplicates(subset=df_train.columns.difference(['id', 'price']))
df_train.shape

for data in [df_train, df_test]:
    for col in data.columns:
        if data[col].dtype != 'object':
            Q1 = data[col].quantile(0.25)
            Q3 = data[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            data[col] = data[col].clip(lower=lower_bound, upper=upper_bound)

"""# **Data Visualization**"""

import warnings

with warnings.catch_warnings():
    warnings.simplefilter("ignore", category=FutureWarning)
    sns.histplot(df_train['price'], bins=30, kde=True)
    plt.title("Price Distribution")
    plt.show()

sns.boxplot(x='airline', y='price', data=df_train)
plt.xticks()
plt.title("Price by Airline")
plt.show()

sns.boxplot(x='stops', y='price', data=df_train)
plt.title("Price by Number of Stops")
plt.show()

df_train_filtered = df_train[df_train['airline'] != 'Unknown']
warnings.simplefilter("ignore", category=FutureWarning)
# Line plot: Avg Price vs Days Left by Airline (excluding Unknown)
sns.lineplot(data=df_train_filtered, x='days_left', y='price', hue='airline', estimator='mean')
plt.title("Avg Price vs Days Left by Airline (Excluding Unknown)")
plt.xlabel("Days Left")
plt.ylabel("Average Price")
plt.show()

df_train.head()

# Separate features and target
df_train["airline_code"] = df_train["flight"].astype(str).str.extract(r"^([A-Z]{1,3})")
df_train['airline_code'] = df_train['airline_code'].fillna('unknown')
df_test["airline_code"] = df_test["flight"].astype(str).str.extract(r"^([A-Z]{1,3})")
df_test['airline_code'] = df_test['airline_code'].fillna('unknown')
df_train = df_train.drop("flight",axis=1)
df_test = df_test.drop("flight",axis=1)
X = df_train.drop(['price', 'id'], axis=1)
y = df_train['price']
test_ids = df_test['id']
df_test = df_test.drop('id', axis=1)

# Split train into train/val
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

num_cols = ['duration', 'days_left']
cat_cols = ['airline','airline_code','source','destination', 'departure', 'arrival', 'class', 'stops']

df_train.head()

encoders = {}

for col in cat_cols:
    le = LabelEncoder()
    le.fit(X_train[col])  # Fit only on training data

    X_train[col] = le.transform(X_train[col])
    X_test[col] = X_test[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)
    df_test[col] = df_test[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)

    encoders[col] = le

scaler = StandardScaler()
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])
df_test[num_cols] = scaler.transform(df_test[num_cols])

X_train.head()

"""# **Data Modelling**"""

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import Pipeline

# === Step 1: Define Raw Models ===
models = {
    "Linear Regression": LinearRegression(),
    "Ridge Regression": Ridge(random_state=42),
    "Lasso Regression": Lasso(random_state=42),
    "Decision Tree Regressor": DecisionTreeRegressor(random_state=42),
    "Random Forest Regressor": RandomForestRegressor(random_state=42, n_jobs=-1),
    "Gradient Boosting Regressor": GradientBoostingRegressor(random_state=42),
    "XGBoost Regressor": XGBRegressor(random_state=42, n_jobs=-1,n_estimators=1000,learning_rate=0.05),
    "LightGBM Regressor": LGBMRegressor(random_state=42, n_jobs=-1, verbosity=-1),
}

# === Step 2: Polynomial Regression Pipelines ===
poly2 = Pipeline([
    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),
    ('regressor', LinearRegression())
])

poly3 = Pipeline([
    ('poly_features', PolynomialFeatures(degree=3, include_bias=False)),
    ('regressor', LinearRegression())
])

# === Step 3: Fit and Evaluate ===
fitted_model = {}
model_metric = {}

# Original models
for model_name, model in models.items():
    print(f"--- Training {model_name} ---")
    model.fit(X_train, y_train)
    fitted_model[model_name] = model

    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    model_metric[model_name] = {"R2": r2, "RMSE": rmse}

    print(f"RMSE: {rmse:.2f}")
    print(f"R2: {r2:.4f}\n")

# Polynomial Regression (deg=3)
print(f"--- Training Polynomial Regression (deg=3) ---")
poly3.fit(X_train, y_train)
y_pred_poly3 = poly3.predict(X_test)
rmse_poly3 = np.sqrt(mean_squared_error(y_test, y_pred_poly3))
r2_poly3 = r2_score(y_test, y_pred_poly3)
fitted_model["Polynomial Regression (deg=3)"] = poly3
model_metric["Polynomial Regression (deg=3)"] = {"R2": r2_poly3, "RMSE": rmse_poly3}
print(f"RMSE: {rmse_poly3:.2f}")
print(f"R2: {r2_poly3:.4f}\n")

params = {
    "Random Forest Regressor": {
        'n_estimators': [50, 100],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5]
    },
    "XGBoost Regressor": {
        'n_estimators': [50, 100],
        'learning_rate': [0.05, 0.1],
        'max_depth': [3, 5]
    },
    "LightGBM Regressor": {
        'n_estimators': [50],
        'learning_rate': [0.05],
        'num_leaves': [20]
    }
}

for model_name, param in params.items():
    print(f"--- Tuning {model_name} ---")

    model = models[model_name]

    grid_search = GridSearchCV(model, param, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=0)
    grid_search.fit(X_train, y_train)

    tuned_model = grid_search.best_estimator_
    fitted_model[model_name] = tuned_model  # replacing our old fitted model with tuned one

    y_pred = tuned_model.predict(X_test)

    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    model_metric[f"{model_name} (tuned)"] = {"R2": r2, "RMSE": rmse}

    print(f"{grid_search.best_params_}\n")

performance_df_train = pd.DataFrame(model_metric).T.sort_values(by='RMSE')
performance_df_train

final_model = fitted_model[performance_df_train.index[0]]
print(final_model)

full_x = pd.concat([X_train, X_test], axis=0)
full_y = pd.concat([y_train, y_test], axis=0)

final_model.fit(full_x, full_y)

test_pred = final_model.predict(df_test)
test_pred = np.clip(test_pred, 0, None)

submission = pd.DataFrame({
    "id": range(df_test.shape[0]),
    "price": test_pred
})
submission.to_csv("submission.csv", index=False)
submission

from IPython.display import FileLink
FileLink("submission.csv")



